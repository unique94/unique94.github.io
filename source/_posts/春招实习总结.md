---
title: 实习面试总结
date: 2018-05-16 19:55:18
tags:
    - Interview
    - Intern
categories:
    - Work
---
&emsp;&emsp;随着滴滴的HR提供了我口头offer，我压力山大的2个月的找春招实习经历总算基本划下了句号。在此总结这两个月以来的辛苦历程（主要记录面试的情况，为之后提供借鉴）。希望自己在未来的日子里，踏踏实实，秋招加油！ 
&emsp;&emsp;本次找实习过程中，本人共经历5场面试（今日头条，阿里AI LAB，高德地图，爱奇异，滴滴出行），全是内推给的机会。可能自己的编程能力有待提高吧，之后秋招要千万注意了。
- 今日头条
    - 时间：3.20
    - 过程：
        - 2面。岗位是NLP实习。时间略久远，不太记得了。
        - 只记得考了两道编程题：一道前序中序，求后序的题；一道二分查找，不小心写了死循环，卒；
        - 觉得同学们以后还是可以问问面试官能不能本机先调调试下，心里有个底还是会好很多，尽量别直接上手写。当然，刷LeetCode真的很重要，能直接撸对代码（不本机调）的能力最好还是有。
- 阿里AI LAB
    - 时间：4.2
    - 过程：
        - 1面。岗位是NLP实习。
        - 全程只聊了自己做的论文工作(aspect-level sentiment classification)，个人觉得聊的还不错，然而凉凉，应该是挂在后面的设计题上了。
        - 设计题：网络上朋友推荐方式——提供一种方式给某用户推荐朋友。想法：基于相同朋友个数的度量方案。算法实现（n个数里取前k大的数）。
        - 现在回想起来，当时面试个人有点浮躁，有点爱抢面试官的话，可能这也是一个非常大的问题吧，之后千万注意。
- 爱奇艺
    - 时间：4.26
    - 过程：
        - 该面试属于内部急召人，不是正常的校招流程，一共只有1面，面试通过了。但隔一天他又说人招到了，也是无语。
        - 讨论论文工作
        - 现实场景题：给你一段选角的文本描述，需要你设计算法选择适合的角色演员，如何做？(大方向是将问题他变为为分类预测问题or基于规则解析文本问题)
- 高德地图
    - 时间：4.28
    - 过程：
        - 2面。岗位是机器学习实习。
        - 一面
            - 论文工作
            - sigmoid函数求导
            - GBDT，XGBoost，RF区别
            - 线程VS进程
            - hadoop
            - TCP3次握手，4次挥手过程
            - 编程题：二分查找
        - 二面
            - 论文工作(指代消解是否了解）
            - bp的推导(对这个我怨念很深；我确定当时我推的完全没有问题，不过因为我的推的是一般形式，不合面试官的口味，他非说我推的不对，当时差点气死)
            - rf的剪枝；rf和gbdt的区别；
            - 最小二乘和极大似然的关联
            - 各大排序算法的时空复杂度情况，手写冒泡排序(当时没练，没注意如果一次遍历未交换数据，即可结束循环)
            - hadoop
            - left join, inner join, right join的区别
            - count(1), count(*), count(字段)的区别
            - python中类变量和成员变量的区别
- 滴滴
    - 时间：5.15，5.16
    - 过程：
        - 岗位为机器学习实习，2面。由同学内推，立马就安排面试了，效率还是非常赞的。
        - 一面
            - 先序遍历非递归实现
            - lambda函数
            - 特征选择方式；如果存在相关性特征，会对逻辑回归有什么影响；如何解决这种影响；
            - 何时要做特征归一化；哪些模型要做特征归一化；特征归一化的好处是什么
            - SGD, SGDM区别；何时用SGD，Adamgrad？如何选择
            - L1如何求解
        - 二面
            - 论文工作(质疑mini-batch=1的结果可能不够好；为何论文中用双向的lstm结果不如单项lstm，如何解释；神经网络的参数如何设定)
            - SGD, SGDM, NAG, Adagrad, Adadelta, Adamgrad, Nadamgrad公式，相互的区别，发展历程
            - XGBoost为何不做三阶talor展开；XGBoost如何做多分类问题；该方式的分类是互斥还是非互斥的；具体的模型参数了解情况；
            - 逻辑回归如何做多分类；是否是互斥的；为何使用sigmoid函数；为什么使用交叉熵/极大似然；最大熵模型；KL散度
            - CRF和HMM的了解

&emsp;&emsp;以上便是我所能回忆起来全部面试内容，在此记录下来，希望能为各位带来帮助
